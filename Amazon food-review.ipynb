{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews=pd.read_csv(\"./datasets/Reviews.csv\")\n",
    "\n",
    "print(reviews.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454, 10)\n"
     ]
    }
   ],
   "source": [
    "print(reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK      dll pa                     0   \n",
      "\n",
      "   HelpfulnessDenominator        Time                Summary  \\\n",
      "0                       1  1303862400  Good Quality Dog Food   \n",
      "1                       0  1346976000      Not as Advertised   \n",
      "\n",
      "                                                Text  \n",
      "0  I have bought several of the Vitality canned d...  \n",
      "1  Product arrived labeled as Jumbo Salted Peanut...  \n"
     ]
    }
   ],
   "source": [
    "seggregated_data=reviews.drop(\"Score\",axis=1)\n",
    "print(seggregated_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posorneg(rev):\n",
    "    if(rev>3):\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Id   ProductId          UserId                      ProfileName  \\\n",
      "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "...        ...         ...             ...                              ...   \n",
      "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
      "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
      "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
      "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
      "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
      "\n",
      "        HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
      "0                          1                       1  positive  1303862400   \n",
      "1                          0                       0  negative  1346976000   \n",
      "2                          1                       1  positive  1219017600   \n",
      "3                          3                       3  negative  1307923200   \n",
      "4                          0                       0  positive  1350777600   \n",
      "...                      ...                     ...       ...         ...   \n",
      "568449                     0                       0  positive  1299628800   \n",
      "568450                     0                       0  negative  1331251200   \n",
      "568451                     2                       2  positive  1329782400   \n",
      "568452                     1                       1  positive  1331596800   \n",
      "568453                     0                       0  positive  1338422400   \n",
      "\n",
      "                                   Summary  \\\n",
      "0                    Good Quality Dog Food   \n",
      "1                        Not as Advertised   \n",
      "2                    \"Delight\" says it all   \n",
      "3                           Cough Medicine   \n",
      "4                              Great taffy   \n",
      "...                                    ...   \n",
      "568449                 Will not do without   \n",
      "568450                        disappointed   \n",
      "568451            Perfect for our maltipoo   \n",
      "568452  Favorite Training and reward treat   \n",
      "568453                         Great Honey   \n",
      "\n",
      "                                                     Text  \n",
      "0       I have bought several of the Vitality canned d...  \n",
      "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2       This is a confection that has been around a fe...  \n",
      "3       If you are looking for the secret ingredient i...  \n",
      "4       Great taffy at a great price.  There was a wid...  \n",
      "...                                                   ...  \n",
      "568449  Great for sesame chicken..this is a good if no...  \n",
      "568450  I'm disappointed with the flavor. The chocolat...  \n",
      "568451  These stars are small, so you can give 10-15 o...  \n",
      "568452  These are the BEST treats for training and rew...  \n",
      "568453  I am very satisfied ,product is as advertised,...  \n",
      "\n",
      "[568454 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "data2=reviews['Score'];\n",
    "newdata=data2.map(posorneg)\n",
    "reviews['Score']=newdata;\n",
    "print(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Drop duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Id   ProductId          UserId  \\\n",
      "150528  150529  0006641040   A25ACLV5KPB4W   \n",
      "150506  150507  0006641040  A1S4A3IQ2MU7V4   \n",
      "150505  150506  0006641040  A2IW4PEEKO2R0U   \n",
      "150504  150505  0006641040  A2PTSM496CF40Z   \n",
      "150503  150504  0006641040   AQEYF1AXARWJZ   \n",
      "...        ...         ...             ...   \n",
      "191720  191721  B009UOFTUI   AJVB004EB0MVK   \n",
      "1477      1478  B009UOFU20   AJVB004EB0MVK   \n",
      "328481  328482  B009UUS05I   ARL20DSHGVM1Y   \n",
      "5702      5703  B009WSNWC4   AMP7K1O84DH1T   \n",
      "327600  327601  B009WVB40S  A3ME78KVX31T21   \n",
      "\n",
      "                                             ProfileName  \\\n",
      "150528                               Matt Hetling \"Matt\"   \n",
      "150506                             sally sue \"sally sue\"   \n",
      "150505                                             Tracy   \n",
      "150504  Jason A. Teeple \"Nobody made a greater mistak...   \n",
      "150503                         Les Sinclair \"book maven\"   \n",
      "...                                                  ...   \n",
      "191720                                 D. Christofferson   \n",
      "1477                                   D. Christofferson   \n",
      "328481                                             Jamie   \n",
      "5702                                                ESTY   \n",
      "327600                                              K'la   \n",
      "\n",
      "        HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
      "150528                     0                       1  positive  1108425600   \n",
      "150506                     1                       1  positive  1191456000   \n",
      "150505                     1                       1  positive  1194739200   \n",
      "150504                     1                       1  positive  1210809600   \n",
      "150503                     1                       1  positive  1212278400   \n",
      "...                      ...                     ...       ...         ...   \n",
      "191720                     0                       0  negative  1345852800   \n",
      "1477                       0                       0  negative  1345852800   \n",
      "328481                     0                       0  positive  1331856000   \n",
      "5702                       0                       0  positive  1351209600   \n",
      "327600                     0                       0  positive  1351123200   \n",
      "\n",
      "                                                  Summary  \\\n",
      "150528                        Nice cadence, catchy rhymes   \n",
      "150506                      chicken soup with rice months   \n",
      "150505         Love the book, miss the hard cover version   \n",
      "150504                                          A classic   \n",
      "150503                             Chicken Soup with Rice   \n",
      "...                                                   ...   \n",
      "191720  weak coffee not good for a premium product and...   \n",
      "1477    weak coffee not good for a premium product and...   \n",
      "328481                                            Perfect   \n",
      "5702                                            DELICIOUS   \n",
      "327600                                             Tasty!   \n",
      "\n",
      "                                                     Text  \n",
      "150528  In June<br />I saw a charming group<br />of ro...  \n",
      "150506  This is a fun way for children to learn their ...  \n",
      "150505  I grew up reading these Sendak books, and watc...  \n",
      "150504  Get the movie or sound track and sing along wi...  \n",
      "150503  A very entertaining rhyming story--cleaver and...  \n",
      "...                                                   ...  \n",
      "191720  This coffee supposedly is premium, it tastes w...  \n",
      "1477    This coffee supposedly is premium, it tastes w...  \n",
      "328481  The basket was the perfect sympathy gift when ...  \n",
      "5702    Purchased this product at a local store in NY ...  \n",
      "327600  I purchased this to send to my son who's away ...  \n",
      "\n",
      "[568454 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "sorted_data=reviews.sort_values(\"ProductId\",axis=0,ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "print(sorted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393933, 10)\n"
     ]
    }
   ],
   "source": [
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "print(final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=final[final.HelpfulnessNumerator<final.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    40027\n",
       "negative    37927\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag Of Words (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 30559)\t1\n",
      "  (0, 32655)\t1\n",
      "  (0, 10797)\t11\n",
      "  (0, 50005)\t1\n",
      "  (0, 13315)\t1\n",
      "  (0, 27590)\t1\n",
      "  (0, 40482)\t5\n",
      "  (0, 49139)\t1\n",
      "  (0, 3948)\t1\n",
      "  (0, 9262)\t1\n",
      "  (0, 57583)\t2\n",
      "  (0, 20548)\t1\n",
      "  (0, 42756)\t1\n",
      "  (0, 56959)\t1\n",
      "  (0, 60023)\t1\n",
      "  (0, 62439)\t3\n",
      "  (0, 13606)\t2\n",
      "  (0, 53140)\t2\n",
      "  (0, 53696)\t3\n",
      "  (0, 40738)\t1\n",
      "  (0, 58828)\t1\n",
      "  (0, 48632)\t1\n",
      "  (0, 57137)\t2\n",
      "  (0, 31893)\t1\n",
      "  (0, 27341)\t1\n",
      "  :\t:\n",
      "  (77953, 4180)\t2\n",
      "  (77953, 63252)\t4\n",
      "  (77953, 62267)\t1\n",
      "  (77953, 57264)\t1\n",
      "  (77953, 35169)\t1\n",
      "  (77953, 35122)\t1\n",
      "  (77953, 40734)\t1\n",
      "  (77953, 39937)\t1\n",
      "  (77953, 36596)\t1\n",
      "  (77953, 47025)\t1\n",
      "  (77953, 4235)\t1\n",
      "  (77953, 29321)\t1\n",
      "  (77953, 40984)\t1\n",
      "  (77953, 51581)\t1\n",
      "  (77953, 58427)\t1\n",
      "  (77953, 40991)\t1\n",
      "  (77953, 24532)\t1\n",
      "  (77953, 37776)\t1\n",
      "  (77953, 19511)\t1\n",
      "  (77953, 26399)\t1\n",
      "  (77953, 20501)\t1\n",
      "  (77953, 10218)\t1\n",
      "  (77953, 18309)\t1\n",
      "  (77953, 16575)\t1\n",
      "  (77953, 36258)\t1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "count_vec=sklearn.feature_extraction.text.CountVectorizer()\n",
    "final_counts=count_vec.fit_transform(final['Text'].values)\n",
    "print(final_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'or', 'were', 'about', 'be', 'down', 'them', 'doesn', \"mustn't\", 'once', 'because', \"weren't\", 'ours', \"you'll\", 'on', 'myself', 'themselves', 'needn', 'over', \"aren't\", \"needn't\", 'the', 'weren', 'when', 'both', 'o', \"wouldn't\", 'these', 'such', 'for', 'me', 'her', 'had', 'than', 'just', 'between', 'aren', \"didn't\", 'their', \"you'd\", 'and', 'm', 'they', 'we', \"shouldn't\", 'before', 'same', 'mightn', 'whom', 'himself', 'she', 'don', 'wasn', 'all', 'having', 'i', 'few', 'most', 'below', 'so', 'will', \"haven't\", 'has', \"doesn't\", 'does', 'very', \"she's\", 'is', 'into', 'being', 'mustn', 'yourselves', 've', 'ma', 'which', 'against', 'only', 'd', 'it', 'under', 'if', 'shan', 're', 'other', 'until', 'can', 'now', 'there', 'his', 'further', 'him', 'itself', \"shan't\", 'some', \"that'll\", 'shouldn', 'ain', 'with', 'more', \"hadn't\", 'your', 'those', 'should', 'yourself', 'did', 'he', 'theirs', 'as', 'herself', 'while', 'who', 'each', 'here', 'any', 'an', \"it's\", 'hasn', 'our', 'then', 'wouldn', 'off', 'been', 'no', 'ourselves', 'my', 'its', 'where', 'this', 'that', 'was', 'during', 'above', 'won', \"you're\", 'why', 'not', 'at', 'own', \"should've\", 'you', \"mightn't\", 'to', 'by', \"you've\", 'hadn', 'are', 'yours', \"isn't\", 'doing', 'nor', 'up', \"hasn't\", 'll', \"won't\", 'a', 'but', 's', 'am', 'isn', 'have', 'after', 'out', 'through', 'of', 'again', \"couldn't\", 'how', 'too', 'couldn', 'hers', 'in', 'what', 't', 'y', 'haven', 'didn', 'from', \"wasn't\", \"don't\", 'do'}\n",
      "**************************************\n",
      "tasti\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop=set(stopwords.words('english'))\n",
    "sno=nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "def cleanhtml(sentence):\n",
    "    cleanr=re.compile('<.*?>')\n",
    "    cleantext=re.sub(cleanr,' ',sentence);\n",
    "    return cleantext\n",
    "def cleanpunc(sentence):\n",
    "    cleaned=re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned=re.sub(r'[.|,|)|(|\\|/]',r'',cleaned)\n",
    "    return cleaned\n",
    "print(stop)\n",
    "print('**************************************')\n",
    "print(sno.stem('tasty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-fed005d7690b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                     \u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/stem/snowball.py\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gener\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"commun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"arsen\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gener\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"arsen\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                 \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[]\n",
    "all_negative_words=[]\n",
    "s=''\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent);\n",
    "    for w in sent.split():\n",
    "        for clean_words in cleanpunc(w).split():\n",
    "            if((clean_words.isalpha() )& (len(clean_words)>2)):\n",
    "                if(clean_words.lower() not in stop):\n",
    "                    s=(sno.stem(clean_words.lower()).encode('utf8'))\n",
    "                    filtered_sentence.append(s);\n",
    "                    if(final['Score'].values[i]=='positive'):\n",
    "                        all_positive_words.append(s);\n",
    "                    else:\n",
    "                        all_negative_words.append(s);\n",
    "                    continue \n",
    "    str1=b\" \".join(filtered_sentence)\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['CleanedText']=final_string\n",
    "print(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
